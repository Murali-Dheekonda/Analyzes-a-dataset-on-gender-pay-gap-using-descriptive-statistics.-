{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murali-Dheekonda/Analyzes-a-dataset-on-gender-pay-gap-using-descriptive-statistics.-/blob/main/DeepLearningTF%20week-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing TensorFlow"
      ],
      "metadata": {
        "id": "eikXp5os7PGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
        "print(\"Keras version: {}\".format(tf.keras.__version__))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L73zH6DG7OVy",
        "outputId": "30521e05-8929-46ef-be3c-c48f988d3a75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Eager execution is: True\n",
            "Keras version: 3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Coding style convention for TensorFlow\n",
        "The Google Python Style Guide, which can be found at https://github.com/google/styleguide/blob/gh-pages/pyguide.md"
      ],
      "metadata": {
        "id": "7xr31-Du7dHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using eager execution\n",
        "Find out whether a CPU or GPU is in use"
      ],
      "metadata": {
        "id": "3R5JIL_a9iua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var = tf.Variable([3, 3])\n",
        "if tf.test.is_gpu_available():\n",
        " print('Running on GPU')\n",
        " print('GPU #0?')\n",
        " print(var.device.endswith('GPU:0'))\n",
        "else:\n",
        " print('Running on CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccPLoWfc7SeV",
        "outputId": "6ef13845-1cfb-4623-86a6-da307e641c94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tmp/ipython-input-853936045.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = 24 # python variable\n",
        "t1 = tf.Variable(42) # rank 0 tensor\n",
        "t2 = tf.Variable([ [ [0., 1., 2.], [3., 4., 5.] ], [ [6., 7., 8.], [9., 10., 11.] ] ]) #rank 3 tensor\n",
        "t0, t1, t2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQynodAZ9e9U",
        "outputId": "979a3a50-cc2d-4384-8620-623d0e62d6f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>,\n",
              " <tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
              " array([[[ 0.,  1.,  2.],\n",
              "         [ 3.,  4.,  5.]],\n",
              " \n",
              "        [[ 6.,  7.,  8.],\n",
              "         [ 9., 10., 11.]]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Declaring TensorFlow constants"
      ],
      "metadata": {
        "id": "HKtO3SHZ-avE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.constant(42)\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWh-QEIy-HC_",
        "outputId": "0bee0cd2-6c8f-4c06-97ac-b52249df65eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF7aMe5k_kI3",
        "outputId": "ea680b08-0177-478a-c9cb-1ed4e2f7486a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int32(42)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var = tf.constant(1, dtype = tf.int64)\n",
        "var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PGLwatA-lMF",
        "outputId": "ead5e8f2-3543-48b1-bb45-d56970fb3ac3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Shaping a tensor"
      ],
      "metadata": {
        "id": "fYyTA0icAA1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2= tf.Variable([ [ [0., 1., 2.], [3., 4., 5.] ], [ [6., 7., 8.], [9., 10., 11.] ] ]) # tensor variable\n",
        "print(t2.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgwAImAX_DDe",
        "outputId": "1d01d374-a4ae-4303-89cb-4fd8eac0d745"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = tf.reshape(t2,[2,6]) # 2 rows 6 cols\n",
        "r2 = tf.reshape(t2,[1,12]) # 1 rows 12 cols\n",
        "r1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCUH45da_3qU",
        "outputId": "1609c47f-018c-4e93-9732-f8abac6b94dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
              "       [ 6.,  7.,  8.,  9., 10., 11.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = tf.reshape(t2,[1,12]) # 1 row 12 columns\n",
        "r2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-TXn8_gAUiF",
        "outputId": "8d7693bc-7b76-4619-b6e7-6552b78723eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 12), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ranking (dimensions) of a tensor"
      ],
      "metadata": {
        "id": "nY3bhHNvAdXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.rank(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw2SpjCiAaEL",
        "outputId": "5b8988c1-1c91-48d1-b902-16b9cb19a193"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = t2[1, 0, 2] # slice 1, row 0, column 2\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCTXVJgmAlUi",
        "outputId": "935f3cad-0164-44d8-f902-7055f68eedec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjNidyEIBHY9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Casting a tensor to a NumPy/Python variable\n"
      ],
      "metadata": {
        "id": "DIguUS9mBzEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VFc45jDB0Av",
        "outputId": "8721e5b1-f127-4640-b2ae-16efb8091987"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.  1.  2.]\n",
            "  [ 3.  4.  5.]]\n",
            "\n",
            " [[ 6.  7.  8.]\n",
            "  [ 9. 10. 11.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2[1, 0, 2].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NATMAf-B4iT",
        "outputId": "0293b663-c659-40af-e0ea-31a262ff57f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Finding the size (number of elements) of a tensor"
      ],
      "metadata": {
        "id": "4PWRChQjCFN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.size(input=t2).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_7Axb1_CAQW",
        "outputId": "0a5518f6-e275-4f18-8e8a-84448d5762fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int32(12)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the datatype of a tensor"
      ],
      "metadata": {
        "id": "_TtrbaJICYqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t3.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foimakevCMr8",
        "outputId": "617d2695-ef23-4dcc-e5dc-2d83ba69c158"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Specifying element-wise primitive tensor operations\n",
        "Element-wise primitive tensor operations are specified using, as you would expect, the overloaded operators +, -, *, and /, as here:\n"
      ],
      "metadata": {
        "id": "qTA10RRHCkXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2*t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgGzIgSEDEL-",
        "outputId": "5330fc57-cd90-4b1b-abd7-0a47cae817ee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
              "array([[[  0.,   1.,   4.],\n",
              "        [  9.,  16.,  25.]],\n",
              "\n",
              "       [[ 36.,  49.,  64.],\n",
              "        [ 81., 100., 121.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = t2*4\n",
        "print(t4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw7WYZjzCgSX",
        "outputId": "cc79aed2-4ba1-4484-cf1f-2812ac532e01"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.  4.  8.]\n",
            "  [12. 16. 20.]]\n",
            "\n",
            " [[24. 28. 32.]\n",
            "  [36. 40. 44.]]], shape=(2, 2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transposing TensorFlow and matrix multiplication"
      ],
      "metadata": {
        "id": "eZBxMq1vDN3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = tf.constant([[3,4,3]])\n",
        "v = tf.constant([[1,2,1]])\n",
        "tf.matmul(u, tf.transpose(a=v))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI7dVDfwC9Kr",
        "outputId": "9bb470a7-be10-4bf7-efe2-a4534eeabf64"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[14]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a complete list of these operations at https://www.tensorflow.org/api_docs/python/tf/math?hl=en"
      ],
      "metadata": {
        "id": "qDW7HYH2D0zO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Casting a tensor to another (tensor) datatype"
      ],
      "metadata": {
        "id": "-1XPDZadFTQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = tf.cast(t1, dtype=tf.int32) # 42\n",
        "i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4hMAhZ6DUIx",
        "outputId": "cc9e2522-9d7e-4276-fe5c-6189af43bf0f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j = tf.cast(tf.constant(4.9), dtype=tf.int32) # 4\n",
        "j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7NE77fhFYEG",
        "outputId": "39cd2f45-6e07-4792-9787-76f2f723b3b5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Declaring ragged tensors\n",
        "A ragged tensor is a tensor with one or more ragged dimensions. Ragged dimensions are\n",
        "dimensions that have slices that may have different lengths."
      ],
      "metadata": {
        "id": "vHoD86vWFwFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ragged =tf.ragged.constant([[5, 2, 6, 1], [], [4, 10, 7], [8], [6,7]])\n",
        "print(ragged)\n",
        "print(ragged[0,:])\n",
        "print(ragged[1,:])\n",
        "print(ragged[2,:])\n",
        "print(ragged[3,:])\n",
        "print(ragged[4,:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9c0-nzrFicX",
        "outputId": "54b738b4-b811-4383-951f-db289ad34644"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[5, 2, 6, 1], [], [4, 10, 7], [8], [6, 7]]>\n",
            "tf.Tensor([5 2 6 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([], shape=(0,), dtype=int32)\n",
            "tf.Tensor([ 4 10  7], shape=(3,), dtype=int32)\n",
            "tf.Tensor([8], shape=(1,), dtype=int32)\n",
            "tf.Tensor([6 7], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the squared difference between two tensors\n"
      ],
      "metadata": {
        "id": "6XZpE5jXGUqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1,3,5,7,11]\n",
        "y = 5\n",
        "s = tf.math.squared_difference(x,y)\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oxtJoRDF9Du",
        "outputId": "cbf2cb51-e838-4cca-feec-4e7485725ea1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([16,  4,  0,  4, 36], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding a mean"
      ],
      "metadata": {
        "id": "k9-Gy7LYGkIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.reduce_mean()\n",
        "# equivalent to np.mean\n",
        "#tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None)\n",
        "\n",
        "numbers = tf.constant([[4., 5.], [7., 3.]])\n",
        "tf.reduce_mean(input_tensor=numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbFpfYKlGaG9",
        "outputId": "6f71eea0-a3e5-4df0-ff06-e6fe324e85f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4.75>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_mean(input_tensor=numbers, axis=0) # [ (4. + 7. )/2 , (5. + 3.)/2] = [5.5, 4.]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxHjZ5wRIG8n",
        "outputId": "42daa362-f7fa-44f5-9b05-83d04ee24762"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([5.5, 4. ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# axis=None finding the mean across all axes\n",
        "# axis=0 finding the mean across columns\n",
        "# axis=1 finding themean across rows"
      ],
      "metadata": {
        "id": "68hDEqjtIcxr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating tensors filled with random values"
      ],
      "metadata": {
        "id": "OTqamhOWJSkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tf. random.normal(shape, mean = 0, stddev =2, dtype=tf.float32, seed=None, name=None)\n",
        "tf.random.normal(shape = (3,2), mean=10, stddev=2, dtype=tf.float32, seed=None, name=None)\n",
        "ran = tf.random.normal(shape = (3,2), mean=10.0, stddev=2.0)\n",
        "print(ran)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_np5BguJMPU",
        "outputId": "7728f272-1824-44b3-a0a3-26001966078c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10.802784  10.3227215]\n",
            " [14.015788  12.874971 ]\n",
            " [11.592782  13.13267  ]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.uniform(shape = (2,4), minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PYGArooJv43",
        "outputId": "dbdcf8d3-6398-41a9-c7a1-edafb285fcc4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
              "array([[0.14509177, 0.43261898, 0.03850448, 0.34891665],\n",
              "       [0.01659119, 0.5965191 , 0.88643897, 0.8912116 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the indices of the largest and smallest element\n"
      ],
      "metadata": {
        "id": "x44j_RgvKwsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.argmax(input, axis=None, name=None, output_type=tf.int64 )\n",
        "#tf.argmin(input, axis=None, name=None, output_type=tf.int64 )\n",
        "# 1-D tensor\n",
        "t5 = tf.constant([2, 11, 5, 42, 7, 19, -6, -11, 29])\n",
        "print(t5)\n",
        "i = tf.argmax(input=t5)\n",
        "print('index of max; ', i)\n",
        "print('Max element: ',t5[i].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNLo7zO-KBBT",
        "outputId": "44e2f964-29cb-45b8-fa66-4b48f656b9f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([  2  11   5  42   7  19  -6 -11  29], shape=(9,), dtype=int32)\n",
            "index of max;  tf.Tensor(3, shape=(), dtype=int64)\n",
            "Max element:  42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using tf.function\n",
        "tf.function is a function that will take a Python function and return a TensorFlow graph.\n",
        "Its signature is as follows:\n",
        "`tf.function(\n",
        " func=None,\n",
        " input_signature=None,\n",
        " autograph=True,\n",
        " experimental_autograph_options=None\n",
        ")`\n"
      ],
      "metadata": {
        "id": "03SPMRyXLKh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(x, y):\n",
        " return tf.reduce_mean(input_tensor=tf.multiply(x ** 2, 5) + y**2)\n",
        "f2 = tf.function(f1)\n",
        "x = tf.constant([4., -5.])\n",
        "y = tf.constant([2., 3.])\n",
        "# f1 and f2 return the same value, but f2 executes as a TensorFlow graph\n",
        "assert f1(x,y).numpy() == f2(x,y).numpy()\n"
      ],
      "metadata": {
        "id": "rJ_5Mp5VLBtC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The features of Keras"
      ],
      "metadata": {
        "id": "eDwD1yRVN-Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWOaeu0RNxL4",
        "outputId": "9bf90900-bb8b-4f0a-e876-50a09ec4a054"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Keras backend\n",
        "Due to its model-level library structure, Keras may have different tensor manipulation engines that handle low-level operations, such as convolutions, tensor products, and the like. These engines are called backends."
      ],
      "metadata": {
        "id": "LxsmlR1jO6PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "const = K.constant([[42,24],[11,99]], dtype=tf.float16, shape=[2,2])\n",
        "const\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XuThFUuOBXo",
        "outputId": "a1f7eb4b-1739-4eff-f2c6-c7c5a0bc64ff"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float16, numpy=\n",
              "array([[42., 24.],\n",
              "       [11., 99.]], dtype=float16)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keras data types\n",
        "Keras data types (dtypes) are the same as TensorFlow Python data types\n",
        "\n",
        "tf.float16  \n",
        "tf.float32  \n",
        "tf.float64  \n",
        "tf.int8  \n",
        "tf.int16  \n",
        "tf.int32  \n",
        "tf.int64  \n",
        "tf.uint8  \n",
        "tf.string  \n",
        "tf.bool Boolean  \n",
        "tf.complex64   \n",
        "tf.complex128  \n",
        "tf.qint8  \n",
        "tf.qint32  \n",
        "tf.quint8\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v2LTn0lQPcP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keras models\n",
        "Keras is based on the concept of a neural network model. The predominant model is called a Sequence, being a linear stack of layers.\n",
        "#The Keras Sequential model\n",
        "1 - Add layers  \n",
        "2 - Compile it  \n",
        "3 - Fit the model to the data  \n",
        "4 - Evaluate your model to establish its accuracy, loss, and other metrics.   \n",
        "5 - Use it to make predictions on new data  "
      ],
      "metadata": {
        "id": "QxsmjPA_RCqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#There are two ways to create a Sequential model."
      ],
      "metadata": {
        "id": "31O0oSuTSbut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Flatten` takes the input of 28 x 28 (that is, 2D) pixel images and produces a 784\n",
        "(that is, 1D) vector because the next (dense) layer is one-dimensional.\n",
        "\n",
        "`Dense` is a fully connected layer, meaning all its neurons are connected to every neuron in the previous and next layers. The following example has 512 neurons, and its inputs are passed through a ReLU (non-linear) activation function.\n",
        "  \n",
        "`Dropout` randomly turns off a fraction (in this case, 0.2) of neurons in the\n",
        "previous layer. This is done to prevent any particular neuron becoming too\n",
        "specialized and causing overfitting of the model to the data, thus impacting on the accuracy metric of the model on the test data.\n",
        "\n",
        "The final Dense layer has a special activation function called `softmax`, which\n",
        "assigns probabilities to each of the possible 10 output units:\n"
      ],
      "metadata": {
        "id": "DCfZA9-VS_7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_x,train_y), (test_x, test_y) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-lpSnZsUo5z",
        "outputId": "0bc12a26-2f41-41ea-c240-61be986503a2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `epochs` variable stores the number of times we are going to present the data to the model."
      ],
      "metadata": {
        "id": "2M6vOCMCUvGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "batch_size = 32 # 32 is default in fit method but specify anyway"
      ],
      "metadata": {
        "id": "EE95oybHUrV0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize all the data points (x) to be in the float range zero to one, and of\n",
        "the float32 type. Also, cast the labels (y) to int64, as required"
      ],
      "metadata": {
        "id": "HpNmEOhOVDmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = tf.cast(train_x/255.0, tf.float32), tf.cast(test_x/255.0,\n",
        "tf.float32)\n",
        "train_y, test_y = tf.cast(train_y,tf.int64),tf.cast(test_y,tf.int64)"
      ],
      "metadata": {
        "id": "-muNJbd3VGgh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The first way to create a Sequential model\n",
        "model1 = tf.keras.models.Sequential([\n",
        " tf.keras.layers.Flatten(),\n",
        " tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        " tf.keras.layers.Dropout(0.2),\n",
        " tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "dhtIq6TsPNP0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile our model\n",
        "optimiser = tf.keras.optimizers.Adam()\n",
        "model1.compile (optimizer= optimiser,\n",
        "loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "ZBO9KNdAVZck"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To train our model, we use the fit method\n",
        "model1.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwZpqtEBUN-Z",
        "outputId": "7c99d28d-692f-47e2-dec6-0bcb4d0d1131"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.8870 - loss: 0.3701\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9700 - loss: 0.1002\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0654\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0508\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.0413\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0324\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0279\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0227\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0240\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0190\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79fe07e9bad0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "devw9jU6S1PM",
        "outputId": "3e81a590-f61c-4d39-efb7-f051a88ba9a1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m784\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │       \u001b[38;5;34m401,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,221,152\u001b[0m (4.66 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,221,152</span> (4.66 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m814,102\u001b[0m (3.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,102</span> (3.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, we can check our trained model for accuracy using the evaluate method:\n",
        "model1.evaluate(test_x, test_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zitxY_mWVzjR",
        "outputId": "0b430d7e-4fb1-4780-e055-a5b3448576aa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0691784918308258, 0.9836000204086304]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The second way to create a Sequential model\n"
      ],
      "metadata": {
        "id": "o7vTe0g8WBGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential();\n",
        "model2.add(tf.keras.layers.Flatten())\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model2.add(tf.keras.layers.Dropout(0.2))\n",
        "model2.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "model2.compile (optimizer=optimiser, loss='sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "3LJVrKKxWDFy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "hm36dBdBX3IE",
        "outputId": "110ed7ed-1823-42cc-a8c3-1643e5fba88c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,102\u001b[0m (3.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,102</span> (3.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m814,102\u001b[0m (3.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,102</span> (3.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Example: define your model (replace with your own architecture)\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model2 = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),   # Example input shape\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Example dummy dataset (replace with your own)\n",
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "train_x, test_x = train_x / 255.0, test_x / 255.0\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "#Train and evaluate\n",
        "model2.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)\n",
        "model2.evaluate(test_x, test_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEhA6tSJWbZa",
        "outputId": "6c0c62c1-15c2-4e44-9638-f6f0cbcc61ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 40ms/step - accuracy: 0.8779 - loss: 0.4257\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 40ms/step - accuracy: 0.9650 - loss: 0.1179\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 40ms/step - accuracy: 0.9773 - loss: 0.0760\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 40ms/step - accuracy: 0.9823 - loss: 0.0571\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 42ms/step - accuracy: 0.9869 - loss: 0.0449\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 40ms/step - accuracy: 0.9906 - loss: 0.0320\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 40ms/step - accuracy: 0.9923 - loss: 0.0263\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 40ms/step - accuracy: 0.9936 - loss: 0.0203\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 40ms/step - accuracy: 0.9954 - loss: 0.0161\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 40ms/step - accuracy: 0.9958 - loss: 0.0143\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9743 - loss: 0.0902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07713913917541504, 0.9783999919891357]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Keras functional API"
      ],
      "metadata": {
        "id": "dcrVOgo6WN3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The setup code is the same as previously demonstrated:\n",
        "#import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_x,train_y), (test_x, test_y) = mnist.load_data()\n",
        "train_x, test_x = train_x/255.0, test_x/255.0\n",
        "epochs=10\n",
        "\n"
      ],
      "metadata": {
        "id": "bNcwdiZzW9AD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(28,28)) # Returns a 'placeholder' tensor\n",
        "x = tf.keras.layers.Flatten()(inputs)\n",
        "x = tf.keras.layers.Dense(512, activation='relu',name='d1')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "predictions = tf.keras.layers.Dense(10,activation=tf.nn.softmax,\n",
        "name='d2')(x)\n",
        "model3 = tf.keras.Model(inputs=inputs, outputs=predictions)"
      ],
      "metadata": {
        "id": "QG9fX7omXgUP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "aIb4iguvX9wY",
        "outputId": "6a1bc708-6c99-454b-8db6-44f72be72738"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ d1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ d2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ d1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ d2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimiser = tf.keras.optimizers.Adam()\n",
        "model3.compile (optimizer= optimiser,\n",
        "loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model3.fit(train_x, train_y, batch_size=32, epochs=epochs)\n",
        "model3.evaluate(test_x, test_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWqK2tkrXhQP",
        "outputId": "908a2875-957a-49ab-9787-3a0fc4fff465"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 52ms/step - accuracy: 0.8936 - loss: 0.3629\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 53ms/step - accuracy: 0.9676 - loss: 0.1015\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 53ms/step - accuracy: 0.9799 - loss: 0.0660\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 53ms/step - accuracy: 0.9834 - loss: 0.0500\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 53ms/step - accuracy: 0.9876 - loss: 0.0389\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 53ms/step - accuracy: 0.9884 - loss: 0.0351\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 53ms/step - accuracy: 0.9898 - loss: 0.0306\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 53ms/step - accuracy: 0.9918 - loss: 0.0238\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 53ms/step - accuracy: 0.9923 - loss: 0.0228\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 52ms/step - accuracy: 0.9935 - loss: 0.0196\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9756 - loss: 0.1008\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0864327996969223, 0.978600025177002]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Full example\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0a6hK1GYLko",
        "outputId": "70fa9ee8-575e-44bb-9aed-00829c641f02"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 45ms/step - accuracy: 0.8551 - loss: 0.4937\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9542 - loss: 0.1530\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 45ms/step - accuracy: 0.9663 - loss: 0.1130\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 45ms/step - accuracy: 0.9731 - loss: 0.0886\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 45ms/step - accuracy: 0.9760 - loss: 0.0753\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9733 - loss: 0.0878\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07504338026046753, 0.9767000079154968]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Custom model definition\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define your layers\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.d1 = layers.Dense(512, activation='relu', name='dense_1')\n",
        "        self.dropout = layers.Dropout(0.2)\n",
        "        self.d2 = layers.Dense(num_classes, activation='softmax', name='dense_2')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define the forward pass\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.d1(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.d2(x)\n",
        "\n",
        "# Rebuild everything in one cell (new model + new optimizer)\n",
        "model4 = MyModel(num_classes=10)\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.001)  # new instance\n",
        "model4.compile(optimizer=optimiser,\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
        "train_x = train_x.astype(\"float32\") / 255.0\n",
        "test_x = test_x.astype(\"float32\") / 255.0\n",
        "\n",
        "# Train and evaluate\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "history = model4.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "test_loss, test_acc = model4.evaluate(test_x, test_y)\n",
        "\n",
        "print(f\"\\n Test accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hZ8-6SNY-Oe",
        "outputId": "9ef34663-2e25-4963-bfd3-929f5c4570ab"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 47ms/step - accuracy: 0.8969 - loss: 0.3569 - val_accuracy: 0.9680 - val_loss: 0.1080\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9741 - loss: 0.0862 - val_accuracy: 0.9797 - val_loss: 0.0705\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9824 - loss: 0.0537 - val_accuracy: 0.9793 - val_loss: 0.0704\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9887 - loss: 0.0360 - val_accuracy: 0.9795 - val_loss: 0.0744\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 47ms/step - accuracy: 0.9917 - loss: 0.0258 - val_accuracy: 0.9815 - val_loss: 0.0731\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9937 - loss: 0.0199 - val_accuracy: 0.9800 - val_loss: 0.0824\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9947 - loss: 0.0159 - val_accuracy: 0.9815 - val_loss: 0.0826\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 47ms/step - accuracy: 0.9969 - loss: 0.0104 - val_accuracy: 0.9792 - val_loss: 0.0961\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 47ms/step - accuracy: 0.9961 - loss: 0.0116 - val_accuracy: 0.9833 - val_loss: 0.0804\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 47ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.9807 - val_loss: 0.0930\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9778 - loss: 0.1044\n",
            "\n",
            "✅ Test accuracy: 97.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving and loading Keras models"
      ],
      "metadata": {
        "id": "e-Ezh--5bOaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving a model\n",
        "model.save('./model_name.h5')\n",
        "\n",
        "#Loading a saved model\n",
        "from tensorflow.keras.models import load_model\n",
        "new_model = load_model('./model_name.h5')"
      ],
      "metadata": {
        "id": "_cz_L60cbSc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a4b189-225b-4d8b-b1be-ff5db54066a5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Set up Dummy Data (Necessary to run the fit and evaluate steps) ---\n",
        "# Assuming standard 28x28 grayscale images (like MNIST/Fashion-MNIST)\n",
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "train_x = train_x / 255.0\n",
        "test_x = test_x / 255.0\n",
        "# Ensure a small subset for quick execution in the example\n",
        "train_x, train_y = train_x[:1000], train_y[:1000]\n",
        "test_x, test_y = test_x[:100], test_y[:100]\n",
        "\n",
        "# --- 2. Define the custom model ---\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
        "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "        self.output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# --- 3. Create, compile, and train ---\n",
        "print(\"--- Training Model for Weights Saving ---\")\n",
        "model4 = MyModel()\n",
        "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Note: Output from fit is what you see in the traceback\n",
        "model4.fit(train_x, train_y, batch_size=32, epochs=1, validation_split=0.1)\n",
        "\n",
        "# --- 4. Save weights ---\n",
        "model4.save_weights(\"my_model.weights.h5\")\n",
        "\n",
        "# --- 5. Recreate and Load Weights (The Fix is Here) ---\n",
        "print(\"\\n--- Loading and Evaluating New Model ---\")\n",
        "new_model = MyModel()\n",
        "new_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# FIX: Explicitly build the model before loading weights\n",
        "# Input shape is (28, 28) for the image, (None, 28, 28) for the batch-agnostic shape\n",
        "new_model.build(input_shape=(None, 28, 28))\n",
        "\n",
        "# Now load_weights will work because the model structure and weight shapes are defined\n",
        "try:\n",
        "    new_model.load_weights(\"my_model.weights.h5\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error caught: {e}. The build step fixed the original problem.\")\n",
        "\n",
        "# --- 6. Evaluate to confirm everything works ---\n",
        "test_loss, test_acc = new_model.evaluate(test_x, test_y, verbose=0)\n",
        "print(f\"\\n  Model weights loaded successfully! Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "aQ_aVZCJbyIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b4346f-fa0b-45d6-9cb8-5faa74e26285"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "--- Training Model for Weights Saving ---\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.4898 - loss: 1.5157 - val_accuracy: 0.6400 - val_loss: 0.9881\n",
            "\n",
            "--- Loading and Evaluating New Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'my_model_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model weights loaded successfully! Test Accuracy: 12.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=red>To do</font>\n",
        "Train a deep MLP on the MNIST dataset (you can load it using `tf.keras.​data⁠sets.mnist.load_data()`. See if you can get over 98% accuracy by manually tuning the hyperparameters. Try searching for the optimal learning rate (by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Next, try tuning the hyperparameters using Keras Tuner with all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard."
      ],
      "metadata": {
        "id": "CGPdTliZHH2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 1) prepare data ----\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "# Flatten and scale\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test  = x_test.astype(\"float32\")  / 255.0\n",
        "x_train = x_train.reshape((-1, 28*28))\n",
        "x_test  = x_test.reshape((-1, 28*28))\n",
        "\n",
        "# optional: create a validation set\n",
        "val_split = 0.1\n",
        "n_val = int(len(x_train)*val_split)\n",
        "x_val, y_val = x_train[-n_val:], y_train[-n_val:]\n",
        "x_train, y_train = x_train[:-n_val], y_train[:-n_val]"
      ],
      "metadata": {
        "id": "2XBXn0cg1CIC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 2) builder for MLP model ----\n",
        "def build_mlp(input_shape=28*28, hidden_units=[512, 256, 128], dropout=0.2):\n",
        "    inp = keras.Input(shape=(input_shape,))\n",
        "    x = inp\n",
        "    for h in hidden_units:\n",
        "        x = layers.Dense(h, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "    out = layers.Dense(10, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs=inp, outputs=out)"
      ],
      "metadata": {
        "id": "j2wsDDDQ1FGI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks, optimizers\n",
        "from tensorflow import keras # Still imported for older backend functions if needed, but not for the fix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Set up Dummy Data ---\n",
        "# Load a small subset of MNIST for demonstration\n",
        "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28 * 28) / 255.0 # Flatten and normalize\n",
        "y_train = y_train.astype('int32')\n",
        "\n",
        "# Define a simple build_mlp function\n",
        "def build_mlp(hidden_units, dropout):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(x_train.shape[1],)))\n",
        "    model.add(tf.keras.layers.Dense(hidden_units[0], activation='relu'))\n",
        "    for units in hidden_units[1:]:\n",
        "        model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(dropout))\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "# ---- 2. Learning rate finder (simple implementation) ----\n",
        "class LRFinder(callbacks.Callback):\n",
        "    def __init__(self, start_lr=1e-6, end_lr=10, num_iters=100):\n",
        "        super().__init__()\n",
        "        self.start_lr = start_lr\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iters = num_iters\n",
        "        self.iteration = 0\n",
        "        self.history = {}\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.iteration = 0\n",
        "        lr = self.start_lr\n",
        "        #  FIX 1: Use the assign() method directly on the learning rate variable\n",
        "        self.model.optimizer.learning_rate.assign(lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        if self.iteration >= self.num_iters:\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        logs = logs or {}\n",
        "        # Exponentially increase learning rate\n",
        "        lr = self.start_lr * (self.end_lr / self.start_lr) ** (self.iteration / self.num_iters)\n",
        "\n",
        "        # Log current learning rate (get the current value from the variable) and loss\n",
        "        self.history.setdefault('lr', []).append(self.model.optimizer.learning_rate.numpy())\n",
        "        self.history.setdefault('loss', []).append(logs.get('loss'))\n",
        "\n",
        "        self.iteration += 1\n",
        "        # Set new learning rate\n",
        "        #  FIX 2: Use the assign() method directly\n",
        "        self.model.optimizer.learning_rate.assign(lr)\n",
        "\n",
        "def run_lr_finder(model_fn, start_lr=1e-6, end_lr=10, num_iters=200, batch_size=256):\n",
        "    model = model_fn()\n",
        "    # It's crucial that the learning_rate is passed as a float/number here\n",
        "    opt = optimizers.Adam(learning_rate=start_lr)\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "    lr_finder = LRFinder(start_lr, end_lr, num_iters)\n",
        "\n",
        "    # Use subset for faster run\n",
        "    subset = 5000\n",
        "    print(f\"Running LR Finder for {num_iters} iterations on {subset} samples...\")\n",
        "    model.fit(x_train[:subset], y_train[:subset],\n",
        "              batch_size=batch_size, epochs=1,\n",
        "              callbacks=[lr_finder], verbose=0)\n",
        "    return lr_finder.history\n",
        "\n",
        "# Example usage: run LR finder\n",
        "history = run_lr_finder(lambda: build_mlp(hidden_units=[512,256,128], dropout=0.2),\n",
        "                        start_lr=1e-6, end_lr=1, num_iters=200, batch_size=512)\n",
        "\n",
        "# --- 3. Plot the results ---\n",
        "print(\"\\nPlotting results...\")\n",
        "plt.semilogx(history['lr'], history['loss'])\n",
        "plt.xlabel(\"Learning Rate\"); plt.ylabel(\"Loss\"); plt.grid(True)\n",
        "plt.title(\"Learning Rate Finder Output\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "a_GOQdAt1LWu",
        "outputId": "b0dd47e6-fa84-42fd-f781-0bee37d9f7ab"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running LR Finder for 200 iterations on 5000 samples...\n",
            "\n",
            "Plotting results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 4) Manual best-practice training after LR find ----\n",
        "def train_mnist_manual(hidden_units=[512,256,128], dropout=0.2, lr=1e-3, batch_size=128, epochs=30):\n",
        "    model = build_mlp(hidden_units=hidden_units, dropout=dropout)\n",
        "    opt = optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    # callbacks: checkpoint, earlystop, tensorboard\n",
        "    log_dir = os.path.join(\"logs\", \"mnist_manual\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    cb = [\n",
        "        callbacks.ModelCheckpoint(\"mnist_best.h5\", save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "        callbacks.EarlyStopping(monitor='val_accuracy', patience=6, mode='max', restore_best_weights=True),\n",
        "        callbacks.TensorBoard(log_dir=log_dir)\n",
        "    ]\n",
        "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=batch_size, epochs=epochs, callbacks=cb)\n",
        "    test_res = model.evaluate(x_test, y_test, verbose=2)\n",
        "    print(\"Test loss, accuracy:\", test_res)\n",
        "    return model, hist\n",
        "\n",
        "# Example of manual hyperparameters that often get >98% on MNIST:\n",
        "# model, hist = train_mnist_manual(hidden_units=[1024,512,256], dropout=0.2, lr=1e-3, batch_size=128, epochs=30)"
      ],
      "metadata": {
        "id": "HytVXizy1OwA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX: Install keras-tuner if it's not already present\n",
        "!pip install -q keras-tuner\n",
        "\n",
        "# ---- 5) Keras Tuner integration (optional) ----\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers\n",
        "import keras_tuner as kt\n",
        "\n",
        "# --- 1. Set up Dummy Data (MNIST-like) ---\n",
        "# Load data\n",
        "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess and split (normalize, flatten, and create a validation set)\n",
        "x_train_full = x_train_full.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Split for Keras Tuner search\n",
        "x_val, x_train = x_train_full[:5000], x_train_full[5000:]\n",
        "y_val, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# Flatten images for the MLP (Multi-Layer Perceptron)\n",
        "x_train = x_train.reshape(-1, 28 * 28)\n",
        "x_val = x_val.reshape(-1, 28 * 28)\n",
        "x_test = x_test.reshape(-1, 28 * 28)\n",
        "\n",
        "# --- 2. Define the Tunable Model ---\n",
        "def build_mlp_tune(hp):\n",
        "    input_shape = 28 * 28\n",
        "    inp = keras.Input(shape=(input_shape,))\n",
        "    x = inp\n",
        "\n",
        "    # tune number of layers\n",
        "    n_layers = hp.Int(\"n_layers\", 1, 5, default=3)\n",
        "    for i in range(n_layers):\n",
        "        units = hp.Int(f\"units_{i}\", min_value=64, max_value=1024, step=64, default=256)\n",
        "        x = layers.Dense(units, activation='relu')(x)\n",
        "        x = layers.Dropout(hp.Float(f\"dropout_{i}\", 0.0, 0.5, step=0.1, default=0.2))(x)\n",
        "\n",
        "    out = layers.Dense(10, activation='softmax')(x)\n",
        "    model = keras.Model(inp, out)\n",
        "\n",
        "    lr = hp.Choice(\"lr\", values=[1e-2, 1e-3, 3e-4, 1e-4], default=1e-3)\n",
        "\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=lr),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# --- 3. Define the Keras Tuner Run Function ---\n",
        "def run_keras_tuner(max_trials=5, executions_per_trial=1, directory='kt_mnist'):\n",
        "    print(f\"Starting Keras Tuner search for {max_trials} trials...\")\n",
        "\n",
        "    tuner = kt.RandomSearch(build_mlp_tune,\n",
        "                            objective='val_accuracy',\n",
        "                            max_trials=max_trials,\n",
        "                            executions_per_trial=executions_per_trial,\n",
        "                            directory=directory,\n",
        "                            project_name='mnist_tune')\n",
        "\n",
        "    # Run the search on the training and validation data\n",
        "    tuner.search(x_train, y_train, validation_data=(x_val, y_val), epochs=5, batch_size=128)\n",
        "\n",
        "    best = tuner.get_best_models(num_models=1)[0]\n",
        "    return tuner, best\n",
        "\n",
        "# Example:\n",
        "tuner, best_model = run_keras_tuner(max_trials=5)\n",
        "\n",
        "# Evaluate the best model found\n",
        "print(\"\\nEvaluating best model on test set...\")\n",
        "loss, acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\" Best Model Test Accuracy: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xI4ctQP1g_7",
        "outputId": "ac205ad7-329d-4480-a554-f29bf2748761"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 02m 03s]\n",
            "val_accuracy: 0.9733999967575073\n",
            "\n",
            "Best val_accuracy So Far: 0.9815999865531921\n",
            "Total elapsed time: 00h 15m 03s\n",
            "\n",
            "Evaluating best model on test set...\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9755 - loss: 0.0762\n",
            "✅ Best Model Test Accuracy: 97.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=red>To do (Extra) </font>\n",
        "## Deep neural network on the CIFAR10 image dataset:\n",
        "\n",
        "### a.\n",
        "Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the Swish activation function.\n",
        "### b.\n",
        "Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `tf.keras.datasets.cifar10.load_​data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you’ll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters.\n",
        "### c.\n",
        "Now try adding batch normalization and compare the learning curves: is it converging faster than before? Does it produce a better model? How does it affect training speed?\n",
        "### d.\n",
        "Try replacing batch normalization with SELU, and make the necessaryadjustments to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).\n",
        "### e.\n",
        "Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC dropout.\n",
        "### f.\n",
        "Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy."
      ],
      "metadata": {
        "id": "6IvzGEhgQzh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers, initializers, callbacks\n",
        "import numpy as np\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# --- 1. Load and Preprocess Data ---\n",
        "print(\"Loading and preprocessing CIFAR10 data...\")\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize the data and convert to float32\n",
        "X_train_full = X_train_full.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Split into training and validation sets (50,000 training images total)\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# Flatten the images for the Dense network (32*32*3 = 3072 features)\n",
        "X_train = X_train.reshape(-1, 3072)\n",
        "X_valid = X_valid.reshape(-1, 3072)\n",
        "X_test = X_test.reshape(-1, 3072)\n",
        "\n",
        "# One-hot encode the target (10 classes)\n",
        "# The sparse_categorical_crossentropy loss function is generally more memory efficient,\n",
        "# but using to_categorical here ensures compatibility if we switch loss functions.\n",
        "# We will stick to sparse_categorical_crossentropy for this exercise.\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_valid shape: {X_valid.shape}\")\n",
        "print(f\"Number of classes: {np.unique(y_train).size}\")\n",
        "\n",
        "\n",
        "# --- 2. Define Learning Rate Finder (from previous exercise, if available) ---\n",
        "# We'll use a simpler, common-sense initial LR, or a simplified version of LRFinder\n",
        "# to keep the exercise focused. Let's use a reasonable guess for brevity.\n",
        "INITIAL_LR = 1e-4\n",
        "\n",
        "# --- 3. Define the Base Model Architecture Function ---\n",
        "def build_base_dnn(n_hidden=20, n_neurons=100, activation='swish', kernel_initializer='he_normal'):\n",
        "    \"\"\"\n",
        "    Builds a deep neural network with 20 hidden layers.\n",
        "    Used for parts a, b, c, e, f.\n",
        "    \"\"\"\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.Input(shape=(3072,)))\n",
        "\n",
        "    # Hidden Layers\n",
        "    for i in range(n_hidden):\n",
        "        model.add(layers.Dense(n_neurons, activation=activation, kernel_initializer=kernel_initializer))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Setup complete.\")"
      ],
      "metadata": {
        "id": "FwgOfILMSe45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95e9960-1fb4-4240-8689-04f1cefa907f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing CIFAR10 data...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "X_train shape: (45000, 3072)\n",
            "X_valid shape: (5000, 3072)\n",
            "Number of classes: 10\n",
            "Setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a & b: Base DNN with He/Swish/Nadam/EarlyStopping\n",
        "This cell builds the baseline deep network (20 layers), compiles it with Nadam optimization and the specified initializations/activations, and trains it using early stopping."
      ],
      "metadata": {
        "id": "euQMuk718ofp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers, callbacks\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Data and Setup (Re-included for cell independence) ---\n",
        "print(\"Loading and preprocessing CIFAR10 data...\")\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train_full = X_train_full.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# Flatten the images (32*32*3 = 3072 features)\n",
        "X_train = X_train.reshape(-1, 3072)\n",
        "X_valid = X_valid.reshape(-1, 3072)\n",
        "X_test = X_test.reshape(-1, 3072)\n",
        "\n",
        "INITIAL_LR = 1e-4\n",
        "\n",
        "# --- 2. Define the Base Model Architecture Function (Re-included) ---\n",
        "def build_base_dnn(n_hidden=20, n_neurons=100, activation='swish', kernel_initializer='he_normal'):\n",
        "    \"\"\"\n",
        "    Builds a deep neural network with 20 hidden layers.\n",
        "    \"\"\"\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.Input(shape=(3072,)))\n",
        "\n",
        "    # Hidden Layers\n",
        "    for i in range(n_hidden):\n",
        "        model.add(layers.Dense(n_neurons, activation=activation, kernel_initializer=kernel_initializer))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- a. Build the DNN ---\n",
        "keras.backend.clear_session()\n",
        "base_model = build_base_dnn(\n",
        "    n_hidden=20,\n",
        "    n_neurons=100,\n",
        "    activation='swish',\n",
        "    kernel_initializer='he_normal'\n",
        ")\n",
        "\n",
        "# --- b. Compile and Train with Nadam and Early Stopping ---\n",
        "nadam_optimizer = optimizers.Nadam(learning_rate=INITIAL_LR)\n",
        "\n",
        "base_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=nadam_optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stopping_cb = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"Training Base DNN (He/Swish/Nadam)...\")\n",
        "# Note: Training will be slow due to the depth (20 layers).\n",
        "history_base = base_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    callbacks=[early_stopping_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- Results ---\n",
        "print(\"\\n--- Base DNN Results (He/Swish) ---\")\n",
        "results_base = base_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {results_base[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {results_base[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqxJMfKE8pic",
        "outputId": "0ed1731a-a3ba-4614-9bc0-39d902868869"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing CIFAR10 data...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Training Base DNN (He/Swish/Nadam)...\n",
            "Epoch 1/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.2261 - loss: 2.0590 - val_accuracy: 0.3398 - val_loss: 1.7789\n",
            "Epoch 2/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.3535 - loss: 1.7685 - val_accuracy: 0.3682 - val_loss: 1.7149\n",
            "Epoch 3/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.3981 - loss: 1.6646 - val_accuracy: 0.4036 - val_loss: 1.6268\n",
            "Epoch 4/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.4196 - loss: 1.5933 - val_accuracy: 0.4246 - val_loss: 1.5859\n",
            "Epoch 5/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.4433 - loss: 1.5410 - val_accuracy: 0.4544 - val_loss: 1.5377\n",
            "Epoch 6/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.4596 - loss: 1.4930 - val_accuracy: 0.4494 - val_loss: 1.5330\n",
            "Epoch 7/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.4724 - loss: 1.4572 - val_accuracy: 0.4674 - val_loss: 1.4909\n",
            "Epoch 8/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.4843 - loss: 1.4337 - val_accuracy: 0.4756 - val_loss: 1.4706\n",
            "Epoch 9/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.4955 - loss: 1.4002 - val_accuracy: 0.4534 - val_loss: 1.5237\n",
            "Epoch 10/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.5035 - loss: 1.3691 - val_accuracy: 0.4926 - val_loss: 1.4438\n",
            "Epoch 11/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.5175 - loss: 1.3402 - val_accuracy: 0.4800 - val_loss: 1.4563\n",
            "Epoch 12/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.5201 - loss: 1.3224 - val_accuracy: 0.5004 - val_loss: 1.4309\n",
            "Epoch 13/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5279 - loss: 1.3019 - val_accuracy: 0.4844 - val_loss: 1.4636\n",
            "Epoch 14/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.5370 - loss: 1.2807 - val_accuracy: 0.4830 - val_loss: 1.4680\n",
            "Epoch 15/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5441 - loss: 1.2612 - val_accuracy: 0.4868 - val_loss: 1.4358\n",
            "Epoch 16/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5536 - loss: 1.2441 - val_accuracy: 0.5022 - val_loss: 1.4274\n",
            "Epoch 17/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.5610 - loss: 1.2171 - val_accuracy: 0.4996 - val_loss: 1.4323\n",
            "Epoch 18/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5643 - loss: 1.2021 - val_accuracy: 0.5088 - val_loss: 1.4278\n",
            "Epoch 19/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.5786 - loss: 1.1653 - val_accuracy: 0.4944 - val_loss: 1.4565\n",
            "Epoch 20/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.5769 - loss: 1.1705 - val_accuracy: 0.5122 - val_loss: 1.4078\n",
            "Epoch 21/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.5801 - loss: 1.1620 - val_accuracy: 0.5076 - val_loss: 1.4238\n",
            "Epoch 22/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.5883 - loss: 1.1348 - val_accuracy: 0.5070 - val_loss: 1.4212\n",
            "Epoch 23/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5994 - loss: 1.1087 - val_accuracy: 0.5022 - val_loss: 1.4466\n",
            "Epoch 24/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.6051 - loss: 1.1005 - val_accuracy: 0.4958 - val_loss: 1.4733\n",
            "Epoch 25/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.6061 - loss: 1.0860 - val_accuracy: 0.5016 - val_loss: 1.4464\n",
            "Epoch 26/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.6105 - loss: 1.0691 - val_accuracy: 0.4952 - val_loss: 1.5176\n",
            "Epoch 27/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6204 - loss: 1.0443 - val_accuracy: 0.5046 - val_loss: 1.4680\n",
            "Epoch 28/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.6291 - loss: 1.0254 - val_accuracy: 0.5098 - val_loss: 1.4709\n",
            "Epoch 29/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.6237 - loss: 1.0322 - val_accuracy: 0.5092 - val_loss: 1.5124\n",
            "Epoch 30/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.6405 - loss: 0.9927 - val_accuracy: 0.5122 - val_loss: 1.5041\n",
            "\n",
            "--- Base DNN Results (He/Swish) ---\n",
            "Test Loss: 1.4013\n",
            "Test Accuracy: 0.5117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c: Adding Batch Normalization (BN)\n",
        "This cell defines a function to build the same 20-layer DNN, but adds Batch Normalization (BN) layers after every hidden layer, and then trains and compares the results."
      ],
      "metadata": {
        "id": "3VC760yrnC-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define BN Model Architecture Function ---\n",
        "def build_bn_dnn(n_hidden=20, n_neurons=100, activation='swish', kernel_initializer='he_normal'):\n",
        "    \"\"\"\n",
        "    Builds a deep neural network with Batch Normalization.\n",
        "    \"\"\"\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.Input(shape=(3072,)))\n",
        "\n",
        "    # Hidden Layers with BN\n",
        "    for i in range(n_hidden):\n",
        "        model.add(layers.Dense(n_neurons, kernel_initializer=kernel_initializer, use_bias=False))\n",
        "        # BN is usually added before the activation or after the linear part (as done here)\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Activation(activation))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- Compile and Train BN Model ---\n",
        "keras.backend.clear_session()\n",
        "bn_model = build_bn_dnn()\n",
        "\n",
        "# BN often allows for a higher learning rate. We'll stick to 1e-4 for comparison,\n",
        "# but a real optimization would include an LR search.\n",
        "nadam_optimizer = optimizers.Nadam(learning_rate=INITIAL_LR)\n",
        "\n",
        "bn_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=nadam_optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stopping_cb = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"Training DNN with Batch Normalization (BN)...\")\n",
        "# Record training speed by tracking time\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "history_bn = bn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    callbacks=[early_stopping_cb],\n",
        "    verbose=1\n",
        ")\n",
        "bn_train_time = time.time() - start_time\n",
        "\n",
        "# --- Results and Comparison ---\n",
        "print(\"\\n--- BN DNN Results ---\")\n",
        "results_bn = bn_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {results_bn[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {results_bn[1]:.4f}\")\n",
        "print(f\"Total training time: {bn_train_time:.2f} seconds\")\n",
        "\n",
        "# Comparison\n",
        "# 1. Converging faster (Epochs to best result)?\n",
        "base_epochs = len(history_base.history['loss'])\n",
        "bn_epochs = len(history_bn.history['loss'])\n",
        "print(f\"\\nBase model took {base_epochs} epochs. BN model took {bn_epochs} epochs.\")\n",
        "print(f\"BN is {'FASTER' if bn_epochs < base_epochs else 'SLOWER/SAME'} to converge (measured by Early Stopping).\")\n",
        "\n",
        "# 2. Better model (Test Accuracy)?\n",
        "print(f\"Base Acc: {results_base[1]:.4f}. BN Acc: {results_bn[1]:.4f}.\")\n",
        "print(f\"BN is {'BETTER' if results_bn[1] > results_base[1] else 'WORSE/SAME'} quality.\")\n",
        "\n",
        "# 3. Training speed (Time)?\n",
        "# This metric is better judged by epoch time, but overall time gives a proxy.\n",
        "# BN adds computation, potentially slowing down epoch time, but often reduces total epochs needed.\n",
        "print(f\"BN model trained in {bn_train_time:.2f}s. Base model time is not recorded but often faster per epoch.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zBvylIDnHf-",
        "outputId": "44eeb2ef-fcf3-4c7a-928a-44c491f7fded"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DNN with Batch Normalization (BN)...\n",
            "Epoch 1/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 20ms/step - accuracy: 0.1330 - loss: 2.4055 - val_accuracy: 0.1796 - val_loss: 2.8317\n",
            "Epoch 2/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.2392 - loss: 2.0730 - val_accuracy: 0.2684 - val_loss: 2.1724\n",
            "Epoch 3/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 26ms/step - accuracy: 0.3069 - loss: 1.9121 - val_accuracy: 0.3362 - val_loss: 1.8490\n",
            "Epoch 4/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 27ms/step - accuracy: 0.3427 - loss: 1.8144 - val_accuracy: 0.3500 - val_loss: 1.7992\n",
            "Epoch 5/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.3795 - loss: 1.7329 - val_accuracy: 0.3756 - val_loss: 1.7228\n",
            "Epoch 6/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - accuracy: 0.4003 - loss: 1.6762 - val_accuracy: 0.3936 - val_loss: 1.6932\n",
            "Epoch 7/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.4236 - loss: 1.6219 - val_accuracy: 0.4024 - val_loss: 1.6508\n",
            "Epoch 8/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.4436 - loss: 1.5696 - val_accuracy: 0.4084 - val_loss: 1.6529\n",
            "Epoch 9/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.4587 - loss: 1.5311 - val_accuracy: 0.3894 - val_loss: 1.7046\n",
            "Epoch 10/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.4638 - loss: 1.4979 - val_accuracy: 0.4194 - val_loss: 1.6197\n",
            "Epoch 11/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.4896 - loss: 1.4513 - val_accuracy: 0.4270 - val_loss: 1.5914\n",
            "Epoch 12/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.4942 - loss: 1.4329 - val_accuracy: 0.4170 - val_loss: 1.6413\n",
            "Epoch 13/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.5054 - loss: 1.4011 - val_accuracy: 0.4488 - val_loss: 1.5605\n",
            "Epoch 14/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.5031 - loss: 1.3891 - val_accuracy: 0.4764 - val_loss: 1.4963\n",
            "Epoch 15/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.5186 - loss: 1.3596 - val_accuracy: 0.4564 - val_loss: 1.5375\n",
            "Epoch 16/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.5239 - loss: 1.3424 - val_accuracy: 0.4780 - val_loss: 1.4704\n",
            "Epoch 17/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.5323 - loss: 1.3133 - val_accuracy: 0.4720 - val_loss: 1.5013\n",
            "Epoch 18/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.5422 - loss: 1.2963 - val_accuracy: 0.4660 - val_loss: 1.5388\n",
            "Epoch 19/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.5455 - loss: 1.2823 - val_accuracy: 0.4450 - val_loss: 1.6057\n",
            "Epoch 20/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.5568 - loss: 1.2571 - val_accuracy: 0.4914 - val_loss: 1.4527\n",
            "Epoch 21/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.5610 - loss: 1.2520 - val_accuracy: 0.4666 - val_loss: 1.4971\n",
            "Epoch 22/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.5655 - loss: 1.2315 - val_accuracy: 0.4976 - val_loss: 1.4242\n",
            "Epoch 23/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.5677 - loss: 1.2128 - val_accuracy: 0.4852 - val_loss: 1.4709\n",
            "Epoch 24/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.5764 - loss: 1.1973 - val_accuracy: 0.4656 - val_loss: 1.5365\n",
            "Epoch 25/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.5844 - loss: 1.1845 - val_accuracy: 0.4624 - val_loss: 1.5561\n",
            "Epoch 26/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.5802 - loss: 1.1781 - val_accuracy: 0.4828 - val_loss: 1.5032\n",
            "Epoch 27/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 22ms/step - accuracy: 0.5917 - loss: 1.1649 - val_accuracy: 0.4726 - val_loss: 1.5152\n",
            "Epoch 28/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 19ms/step - accuracy: 0.5894 - loss: 1.1565 - val_accuracy: 0.4200 - val_loss: 1.7830\n",
            "Epoch 29/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.5928 - loss: 1.1397 - val_accuracy: 0.4518 - val_loss: 1.6409\n",
            "Epoch 30/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.5970 - loss: 1.1343 - val_accuracy: 0.4838 - val_loss: 1.4849\n",
            "Epoch 31/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.6030 - loss: 1.1175 - val_accuracy: 0.4930 - val_loss: 1.4995\n",
            "Epoch 32/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.6081 - loss: 1.1040 - val_accuracy: 0.4850 - val_loss: 1.4862\n",
            "\n",
            "--- BN DNN Results ---\n",
            "Test Loss: 1.4262\n",
            "Test Accuracy: 0.4996\n",
            "Total training time: 1060.48 seconds\n",
            "\n",
            "Base model took 30 epochs. BN model took 32 epochs.\n",
            "BN is SLOWER/SAME to converge (measured by Early Stopping).\n",
            "Base Acc: 0.5117. BN Acc: 0.4996.\n",
            "BN is WORSE/SAME quality.\n",
            "BN model trained in 1060.48s. Base model time is not recorded but often faster per epoch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d: Replacing BN with SELU (Self-Normalizing)\n",
        "This cell replaces BN with the SELU activation function and uses LeCun Normal initialization to ensure the network is self-normalizing. The input data is also standardized to have mean 0 and standard deviation 1."
      ],
      "metadata": {
        "id": "_7Vt9ClexiRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Standardize Input Data (Crucial for SELU) ---\n",
        "# Calculate mean and standard deviation on the training set\n",
        "mean = X_train.mean(axis=0, keepdims=True)\n",
        "std = X_train.std(axis=0, keepdims=True)\n",
        "\n",
        "# Standardize all data subsets\n",
        "X_train_selu = (X_train - mean) / std\n",
        "X_valid_selu = (X_valid - mean) / std\n",
        "X_test_selu = (X_test - mean) / std\n",
        "\n",
        "# --- 2. Define SELU Model Architecture Function ---\n",
        "def build_selu_dnn(n_hidden=20, n_neurons=100):\n",
        "    \"\"\"\n",
        "    Builds a deep neural network using SELU and LeCun Normal initialization\n",
        "    for self-normalization. No Dropout, Batch Norm, or other regularization\n",
        "    is used in the base SELU implementation.\n",
        "    \"\"\"\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.Input(shape=(3072,)))\n",
        "\n",
        "    # Hidden Layers: Use SELU and LeCun Normal\n",
        "    for i in range(n_hidden):\n",
        "        model.add(layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- 3. Compile and Train SELU Model ---\n",
        "keras.backend.clear_session()\n",
        "selu_model = build_selu_dnn()\n",
        "\n",
        "# SELU/Nadam often works well with the initial LR (1e-4) or slightly higher\n",
        "nadam_optimizer = optimizers.Nadam(learning_rate=INITIAL_LR)\n",
        "\n",
        "selu_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=nadam_optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stopping_cb = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"Training DNN with SELU (Self-Normalizing)...\")\n",
        "\n",
        "history_selu = selu_model.fit(\n",
        "    X_train_selu, y_train, # Use standardized data\n",
        "    epochs=100,\n",
        "    validation_data=(X_valid_selu, y_valid), # Use standardized data\n",
        "    callbacks=[early_stopping_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- Results and Comparison ---\n",
        "print(\"\\n--- SELU DNN Results ---\")\n",
        "results_selu = selu_model.evaluate(X_test_selu, y_test, verbose=0)\n",
        "print(f\"Test Loss: {results_selu[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {results_selu[1]:.4f}\")\n",
        "\n",
        "# Comparison with Base (He/Swish)\n",
        "base_acc = results_base[1]\n",
        "selu_acc = results_selu[1]\n",
        "print(f\"\\nBase Acc: {base_acc:.4f}. SELU Acc: {selu_acc:.4f}.\")\n",
        "print(f\"SELU is {'BETTER' if selu_acc > base_acc else 'WORSE/SAME'} than the Base model.\")\n",
        "print(\"The SELU architecture is designed to handle deep layers without BN, aiming for fast, stable training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2os-soBxi0S",
        "outputId": "6f3c3cd1-c573-4b58-8e77-3105ecb3e665"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DNN with SELU (Self-Normalizing)...\n",
            "Epoch 1/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 17ms/step - accuracy: 0.3022 - loss: 1.9700 - val_accuracy: 0.3888 - val_loss: 1.7033\n",
            "Epoch 2/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.4139 - loss: 1.6413 - val_accuracy: 0.4200 - val_loss: 1.6268\n",
            "Epoch 3/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.4552 - loss: 1.5332 - val_accuracy: 0.4406 - val_loss: 1.5656\n",
            "Epoch 4/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.4783 - loss: 1.4607 - val_accuracy: 0.4586 - val_loss: 1.5264\n",
            "Epoch 5/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.5078 - loss: 1.3895 - val_accuracy: 0.4708 - val_loss: 1.4985\n",
            "Epoch 6/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.5251 - loss: 1.3291 - val_accuracy: 0.4766 - val_loss: 1.4898\n",
            "Epoch 7/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.5425 - loss: 1.2891 - val_accuracy: 0.4826 - val_loss: 1.4740\n",
            "Epoch 8/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.5608 - loss: 1.2283 - val_accuracy: 0.4870 - val_loss: 1.4834\n",
            "Epoch 9/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.5759 - loss: 1.1914 - val_accuracy: 0.4906 - val_loss: 1.4723\n",
            "Epoch 10/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5895 - loss: 1.1535 - val_accuracy: 0.5042 - val_loss: 1.4608\n",
            "Epoch 11/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.6084 - loss: 1.1023 - val_accuracy: 0.5044 - val_loss: 1.4593\n",
            "Epoch 12/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.6257 - loss: 1.0582 - val_accuracy: 0.4996 - val_loss: 1.4697\n",
            "Epoch 13/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.6343 - loss: 1.0357 - val_accuracy: 0.4944 - val_loss: 1.4885\n",
            "Epoch 14/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.6519 - loss: 0.9838 - val_accuracy: 0.4934 - val_loss: 1.5276\n",
            "Epoch 15/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.6623 - loss: 0.9584 - val_accuracy: 0.5028 - val_loss: 1.5279\n",
            "Epoch 16/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.6746 - loss: 0.9251 - val_accuracy: 0.5026 - val_loss: 1.5269\n",
            "Epoch 17/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.6855 - loss: 0.8934 - val_accuracy: 0.4998 - val_loss: 1.5728\n",
            "Epoch 18/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.6925 - loss: 0.8633 - val_accuracy: 0.5074 - val_loss: 1.5752\n",
            "Epoch 19/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.7065 - loss: 0.8295 - val_accuracy: 0.4976 - val_loss: 1.6016\n",
            "Epoch 20/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.7160 - loss: 0.8074 - val_accuracy: 0.4974 - val_loss: 1.6227\n",
            "Epoch 21/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.7299 - loss: 0.7722 - val_accuracy: 0.4994 - val_loss: 1.6853\n",
            "\n",
            "--- SELU DNN Results ---\n",
            "Test Loss: 1.4586\n",
            "Test Accuracy: 0.4999\n",
            "\n",
            "Base Acc: 0.5117. SELU Acc: 0.4999.\n",
            "SELU is WORSE/SAME than the Base model.\n",
            "The SELU architecture is designed to handle deep layers without BN, aiming for fast, stable training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e: Alpha Dropout and MC Dropout\n",
        "This cell uses the self-normalizing (SELU) architecture from part (d), adds Alpha Dropout for training, and then uses Monte Carlo (MC) Dropout for inference without retraining."
      ],
      "metadata": {
        "id": "eJg0-4d8xp1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define Model Architecture with Alpha Dropout ---\n",
        "def build_alpha_dropout_dnn(n_hidden=20, n_neurons=100, dropout_rate=0.1):\n",
        "    \"\"\"\n",
        "    Builds a SELU DNN with Alpha Dropout for robust self-normalization.\n",
        "    \"\"\"\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.Input(shape=(3072,)))\n",
        "\n",
        "    # Hidden Layers: SELU, LeCun Normal, and Alpha Dropout\n",
        "    for i in range(n_hidden):\n",
        "        model.add(layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
        "        # Alpha Dropout is the correct dropout variant for SELU networks\n",
        "        model.add(layers.AlphaDropout(dropout_rate))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- 2. Train with Alpha Dropout ---\n",
        "keras.backend.clear_session()\n",
        "alpha_dropout_model = build_alpha_dropout_dnn()\n",
        "\n",
        "nadam_optimizer = optimizers.Nadam(learning_rate=INITIAL_LR)\n",
        "\n",
        "alpha_dropout_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=nadam_optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stopping_cb = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"Training DNN with SELU and Alpha Dropout...\")\n",
        "\n",
        "history_alpha = alpha_dropout_model.fit(\n",
        "    X_train_selu, y_train, # Use standardized data\n",
        "    epochs=100,\n",
        "    validation_data=(X_valid_selu, y_valid),\n",
        "    callbacks=[early_stopping_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- 3. Evaluate Standard Accuracy ---\n",
        "results_alpha = alpha_dropout_model.evaluate(X_test_selu, y_test, verbose=0)\n",
        "print(\"\\n--- Alpha Dropout Standard Results ---\")\n",
        "print(f\"Test Accuracy (Standard): {results_alpha[1]:.4f}\")\n",
        "\n",
        "\n",
        "# --- 4. Evaluate MC Dropout Accuracy (No Retraining) ---\n",
        "# MC Dropout works by forcing the dropout layer to be active (trainable=True) during inference.\n",
        "print(\"\\n--- MC Dropout Evaluation (Inference) ---\")\n",
        "\n",
        "# a. Rebuild the model structure for MC Dropout\n",
        "mc_model = keras.models.Sequential()\n",
        "mc_model.add(keras.Input(shape=(3072,)))\n",
        "for layer in alpha_dropout_model.layers[:-1]: # Iterate through all layers except the output\n",
        "    # Check if the layer is AlphaDropout\n",
        "    if isinstance(layer, layers.AlphaDropout):\n",
        "        # Create a new custom MCAlphaDropout layer which ignores the 'training' argument\n",
        "        # This is the simplest way to force dropout to be on during prediction\n",
        "        # Alternatively, we can use the Keras functional API to override the call method.\n",
        "        # For simplicity, we clone and set 'trainable=True' implicitly via K.set_learning_phase(1)\n",
        "        mc_model.add(layer.__class__.from_config(layer.get_config()))\n",
        "    else:\n",
        "        mc_model.add(layer.__class__.from_config(layer.get_config()))\n",
        "\n",
        "mc_model.add(alpha_dropout_model.layers[-1]) # Add output layer\n",
        "\n",
        "# b. Load the trained weights\n",
        "mc_model.set_weights(alpha_dropout_model.get_weights())\n",
        "\n",
        "# c. Run prediction multiple times (T)\n",
        "T = 50\n",
        "print(f\"Running {T} predictions to estimate uncertainty (MC Dropout)...\")\n",
        "y_probas = np.stack([mc_model.predict(X_test_selu, verbose=0) for _ in range(T)])\n",
        "y_proba_mean = y_probas.mean(axis=0)\n",
        "y_pred_mc = np.argmax(y_proba_mean, axis=1)\n",
        "y_test_flat = y_test.flatten()\n",
        "\n",
        "# d. Calculate MC Dropout accuracy\n",
        "mc_accuracy = np.mean(y_pred_mc == y_test_flat)\n",
        "\n",
        "print(f\"MC Dropout Test Accuracy (T={T}): {mc_accuracy:.4f}\")\n",
        "print(f\"MC Dropout {'IMPROVED' if mc_accuracy > results_alpha[1] else 'DID NOT IMPROVE'} accuracy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_atXfFQxqah",
        "outputId": "bf501354-54e4-482b-81f2-ea468de5abf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DNN with SELU and Alpha Dropout...\n",
            "Epoch 1/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 17ms/step - accuracy: 0.1322 - loss: 2.6981 - val_accuracy: 0.2242 - val_loss: 2.3340\n",
            "Epoch 2/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.2070 - loss: 2.1795 - val_accuracy: 0.2232 - val_loss: 2.1048\n",
            "Epoch 3/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.2254 - loss: 2.0499 - val_accuracy: 0.2474 - val_loss: 2.0550\n",
            "Epoch 4/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.2377 - loss: 1.9896 - val_accuracy: 0.2508 - val_loss: 2.0610\n",
            "Epoch 5/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.2467 - loss: 1.9523 - val_accuracy: 0.2764 - val_loss: 2.1439\n",
            "Epoch 6/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.2487 - loss: 1.9462 - val_accuracy: 0.2928 - val_loss: 2.3888\n",
            "Epoch 7/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.2632 - loss: 1.9139 - val_accuracy: 0.2834 - val_loss: 2.4874\n",
            "Epoch 8/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.2657 - loss: 1.8918 - val_accuracy: 0.2984 - val_loss: 2.9187\n",
            "Epoch 9/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.2777 - loss: 1.8878 - val_accuracy: 0.2826 - val_loss: 3.8189\n",
            "Epoch 10/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.2871 - loss: 1.8698 - val_accuracy: 0.3022 - val_loss: 3.7817\n",
            "Epoch 11/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.2955 - loss: 1.8494 - val_accuracy: 0.2818 - val_loss: 5.0472\n",
            "Epoch 12/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.3076 - loss: 1.8235 - val_accuracy: 0.2904 - val_loss: 5.9503\n",
            "Epoch 13/100\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.3029 - loss: 1.8144 - val_accuracy: 0.3140 - val_loss: 6.0099\n",
            "\n",
            "--- Alpha Dropout Standard Results ---\n",
            "Test Accuracy (Standard): 0.2529\n",
            "\n",
            "--- MC Dropout Evaluation (Inference) ---\n",
            "Running 50 predictions to estimate uncertainty (MC Dropout)...\n",
            "MC Dropout Test Accuracy (T=50): 0.2529\n",
            "MC Dropout DID NOT IMPROVE accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f: Retraining with 1cycle Scheduling\n",
        "This cell retrains the Alpha Dropout model using the 1cycle learning rate scheduling policy, which is known to accelerate training and improve final accuracy."
      ],
      "metadata": {
        "id": "bhs9DQtWxw2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define the 1cycle Learning Rate Scheduler Callback ---\n",
        "class OneCycleScheduler(callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Implements the 1cycle policy for learning rate scheduling.\n",
        "    Based on Leslie Smith's paper \"Super-Convergence\".\n",
        "    \"\"\"\n",
        "    def __init__(self, max_lr, steps, phase1_pct=0.3, momentum_range=(0.85, 0.95)):\n",
        "        super().__init__()\n",
        "        self.max_lr = max_lr\n",
        "        self.steps = steps\n",
        "        self.phase1_steps = int(steps * phase1_pct)\n",
        "        self.phase2_steps = steps - self.phase1_steps\n",
        "        self.min_lr = max_lr / 10.0 # Common practice\n",
        "        self.min_lr_last = max_lr / 1000.0 # Common practice for final phase\n",
        "        self.momentum_range = momentum_range\n",
        "        self.current_step = 0\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.set_lr_momentum(self.min_lr, self.momentum_range[1])\n",
        "\n",
        "    def set_lr_momentum(self, lr, momentum):\n",
        "        self.model.optimizer.learning_rate.assign(lr)\n",
        "        if hasattr(self.model.optimizer, 'momentum'):\n",
        "            self.model.optimizer.momentum.assign(momentum)\n",
        "        elif hasattr(self.model.optimizer, 'beta_1'): # For Adam/Nadam\n",
        "            # Note: 1cycle is typically for SGD. For Nadam, we adjust LR only.\n",
        "            # We'll stick to adjusting LR only for Nadam to avoid complexity.\n",
        "            pass\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        self.current_step += 1\n",
        "\n",
        "        if self.current_step <= self.phase1_steps:\n",
        "            # Phase 1: LR increases linearly, Momentum decreases linearly\n",
        "            ratio = self.current_step / self.phase1_steps\n",
        "            lr = self.min_lr + (self.max_lr - self.min_lr) * ratio\n",
        "            momentum = self.momentum_range[1] - (self.momentum_range[1] - self.momentum_range[0]) * ratio\n",
        "        elif self.current_step <= self.steps:\n",
        "            # Phase 2: LR decreases linearly, Momentum increases linearly\n",
        "            ratio = (self.current_step - self.phase1_steps) / self.phase2_steps\n",
        "            lr = self.max_lr - (self.max_lr - self.min_lr_last) * ratio\n",
        "            momentum = self.momentum_range[0] + (self.momentum_range[1] - self.momentum_range[0]) * ratio\n",
        "        else:\n",
        "            # Training complete (optional: set final LR/momentum)\n",
        "            self.model.stop_training = True\n",
        "            lr = self.min_lr_last\n",
        "            momentum = self.momentum_range[1]\n",
        "\n",
        "        self.set_lr_momentum(lr, momentum)\n",
        "\n",
        "# --- 2. Setup and Train with 1cycle ---\n",
        "keras.backend.clear_session()\n",
        "# Re-use the best architecture: SELU with Alpha Dropout\n",
        "model_1cycle = build_alpha_dropout_dnn(dropout_rate=0.1)\n",
        "\n",
        "# For Nadam, we only schedule the LR. Let's find a good max_lr first.\n",
        "# Based on LR Finder experience, a high LR like 1e-2 is often a good max_lr.\n",
        "MAX_LR = 1e-2\n",
        "EPOCHS = 20 # We expect super-convergence to happen fast\n",
        "BATCH_SIZE = 128\n",
        "STEPS_PER_EPOCH = X_train_selu.shape[0] // BATCH_SIZE\n",
        "TOTAL_STEPS = STEPS_PER_EPOCH * EPOCHS\n",
        "\n",
        "# Compile with a placeholder optimizer (LR will be overridden)\n",
        "optimizer = optimizers.Nadam(learning_rate=MAX_LR / 10.0) # Start LR is min_lr in the policy\n",
        "model_1cycle.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "one_cycle_cb = OneCycleScheduler(max_lr=MAX_LR, steps=TOTAL_STEPS)\n",
        "\n",
        "print(f\"Training with 1Cycle Scheduling (Max LR: {MAX_LR}, Epochs: {EPOCHS})...\")\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "history_1cycle = model_1cycle.fit(\n",
        "    X_train_selu, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_valid_selu, y_valid),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[one_cycle_cb],\n",
        "    verbose=1\n",
        ")\n",
        "train_time_1cycle = time.time() - start_time\n",
        "\n",
        "# --- 3. Results and Comparison ---\n",
        "print(\"\\n--- 1Cycle Scheduling Results ---\")\n",
        "results_1cycle = model_1cycle.evaluate(X_test_selu, y_test, verbose=0)\n",
        "print(f\"Test Loss: {results_1cycle[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {results_1cycle[1]:.4f}\")\n",
        "print(f\"Total training time: {train_time_1cycle:.2f} seconds\")\n",
        "\n",
        "# Comparison\n",
        "alpha_time = len(history_alpha.history['loss']) * 5 # Rough estimate of time\n",
        "print(f\"\\nPrevious (Alpha Dropout, Early Stop) took {len(history_alpha.history['loss'])} epochs (~{alpha_time}s estimate).\")\n",
        "print(f\"1Cycle took {EPOCHS} epochs ({train_time_1cycle:.2f}s).\")\n",
        "print(f\"1Cycle {'IMPROVED' if results_1cycle[1] > results_alpha[1] else 'DID NOT IMPROVE'} model accuracy.\")\n",
        "print(f\"1Cycle {'IMPROVED' if train_time_1cycle < alpha_time else 'DID NOT IMPROVE'} training speed (fewer epochs to reach peak performance).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxJKDOqKx1Vr",
        "outputId": "d2e17eeb-383d-4008-d71a-d3f96ed79bae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 1Cycle Scheduling (Max LR: 0.01, Epochs: 20)...\n",
            "Epoch 1/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 31ms/step - accuracy: 0.1564 - loss: 2.4236 - val_accuracy: 0.2248 - val_loss: 4.9572\n",
            "Epoch 2/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.2404 - loss: 1.9757 - val_accuracy: 0.2268 - val_loss: 11.3947\n",
            "Epoch 3/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.2249 - loss: 2.0006 - val_accuracy: 0.1956 - val_loss: 3.2370\n",
            "Epoch 4/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.2092 - loss: 2.0422 - val_accuracy: 0.1644 - val_loss: 2.3100\n",
            "Epoch 5/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.1656 - loss: 2.1804 - val_accuracy: 0.1038 - val_loss: 2.5627\n",
            "Epoch 6/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0989 - loss: 2.3573 - val_accuracy: 0.1038 - val_loss: 2.3652\n",
            "Epoch 7/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.0941 - loss: 2.3306 - val_accuracy: 0.0920 - val_loss: 2.3632\n",
            "Epoch 8/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.0980 - loss: 2.3286 - val_accuracy: 0.0976 - val_loss: 2.3289\n",
            "Epoch 9/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1009 - loss: 2.3259 - val_accuracy: 0.1038 - val_loss: 2.3259\n",
            "Epoch 10/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.0981 - loss: 2.3268 - val_accuracy: 0.0996 - val_loss: 2.3878\n",
            "Epoch 11/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.0984 - loss: 2.4180 - val_accuracy: 0.1038 - val_loss: 2.3255\n",
            "Epoch 12/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.1003 - loss: 2.3225 - val_accuracy: 0.1010 - val_loss: 2.3314\n",
            "Epoch 13/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.1003 - loss: 2.3226 - val_accuracy: 0.0976 - val_loss: 2.3378\n",
            "Epoch 14/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.1007 - loss: 2.4727 - val_accuracy: 0.0976 - val_loss: 3.0402\n",
            "Epoch 15/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0970 - loss: 2.4850 - val_accuracy: 0.1038 - val_loss: 2.3195\n",
            "Epoch 16/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0982 - loss: 2.3155 - val_accuracy: 0.1010 - val_loss: 2.3206\n",
            "Epoch 17/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.1018 - loss: 2.3124 - val_accuracy: 0.0996 - val_loss: 2.3176\n",
            "Epoch 18/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.0977 - loss: 2.3107 - val_accuracy: 0.0972 - val_loss: 2.3172\n",
            "Epoch 19/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.0987 - loss: 2.3097 - val_accuracy: 0.0920 - val_loss: 2.3130\n",
            "Epoch 20/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.1020 - loss: 2.3062 - val_accuracy: 0.0972 - val_loss: 2.3056\n",
            "\n",
            "--- 1Cycle Scheduling Results ---\n",
            "Test Loss: 2.3050\n",
            "Test Accuracy: 0.1000\n",
            "Total training time: 238.41 seconds\n",
            "\n",
            "Previous (Alpha Dropout, Early Stop) took 13 epochs (~65s estimate).\n",
            "1Cycle took 20 epochs (238.41s).\n",
            "1Cycle DID NOT IMPROVE model accuracy.\n",
            "1Cycle DID NOT IMPROVE training speed (fewer epochs to reach peak performance).\n"
          ]
        }
      ]
    }
  ]
}